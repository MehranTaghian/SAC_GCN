TODO are as follows:

1) The fill_value argument was removed in torch-scatter>=2.0.0 as it introduced a lot of problems for scatter_max.
In scatter_max, we usually want to fill missing values with zero, while we also want to allow negative output values
as a result of grouping only negative values (rather than set this to 0 by default).

If you want to restore the old behavior, you can define out before-hand and set it to your desired fill_value:
out = src.new_zeros(output_shape)
scatter_max(src, index, dim=..., out=out)

2) based on the relevance score of the joint, find how much time it takes to adapt for each fault occured
 to those joints with positive scores, and how detrimental the fault would be.

3) Why are you using your left hand to write? Because my right hand is damaged -> my dynamics changed. In life-long learning,
we can analyze the change in the policy and change in the pattern of relevance scores.

4) design an experiment for a specific joint to malfunction and misbehave (move accidentally more than
what desired)

5) Occlude all the mandatory joints.

6) change the action space to set the joint velocities.

screen 516512.pts-7.melco on melco:
uses joint velocities. If this does not work, change pos_ctrl *= 1 to pos_ctrl *= 10 in fetch_env.py

screen on mehran:
Occlude all the mandatory joints. Joints having highest relevance scores.

7) simulate experiments in which when an action is applied to move a joint in some specific direction, move that
joint to the other side so to move against decision-making

